#!/usr/bin/env python3
"""
OpenAI APIë¥¼ í™œìš©í•œ ê³ í’ˆì§ˆ RAG ì‹œìŠ¤í…œ
"""

import os
import logging
from improved_rag import ImprovedTourismRAG
import requests
import json

logger = logging.getLogger(__name__)

class OpenAITourismRAG(ImprovedTourismRAG):
    def __init__(self, data_folder="./data", similarity_threshold=0.1, api_key=None):
        super().__init__(data_folder, similarity_threshold)
        self.api_key = api_key or os.getenv('OPENAI_API_KEY')
        
    def call_openai_api(self, messages, model="gpt-4o-mini"):
        """OpenAI API í˜¸ì¶œ"""
        if not self.api_key:
            return None
            
        url = "https://api.openai.com/v1/chat/completions"
        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json"
        }
        
        data = {
            "model": model,
            "messages": messages,
            "max_tokens": 800,
            "temperature": 0.3,
            "top_p": 0.9
        }
        
        try:
            response = requests.post(url, headers=headers, json=data, timeout=30)
            response.raise_for_status()
            return response.json()
        except Exception as e:
            logger.error(f"OpenAI API í˜¸ì¶œ ì‹¤íŒ¨: {e}")
            return None

    def generate_answer_with_openai(self, question):
        """OpenAI APIë¥¼ ì‚¬ìš©í•œ ê³ í’ˆì§ˆ ë‹µë³€ ìƒì„±"""
        retrieved_docs, sources = self.query(question, top_k=5)
        
        if not retrieved_docs:
            return "ê´€ë ¨ëœ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.", []
        
        # ì»¨í…ìŠ¤íŠ¸ ì¤€ë¹„
        context = "\n\n".join(retrieved_docs[:3])
        
        messages = [
            {
                "role": "system",
                "content": """ë‹¹ì‹ ì€ í•œêµ­ ê´€ê´‘ ì „ë¬¸ AI ë„ìš°ë¯¸ì…ë‹ˆë‹¤. 

ì£¼ì–´ì§„ ìë£Œë¥¼ ë°”íƒ•ìœ¼ë¡œ ì •í™•í•˜ê³  ìœ ìš©í•œ ì •ë³´ë¥¼ ì œê³µí•˜ì„¸ìš”.

ë‹µë³€ ì›ì¹™:
1. ì œê³µëœ ìë£Œë§Œì„ ê·¼ê±°ë¡œ ë‹µë³€
2. ìë£Œì— ì—†ëŠ” ë‚´ìš©ì€ ì¶”ì¸¡í•˜ì§€ ë§ ê²ƒ
3. êµ¬ì¡°í™”ë˜ê³  ì½ê¸° ì‰¬ìš´ í˜•íƒœë¡œ ì‘ì„±
4. í•µì‹¬ ë‚´ìš©ì„ ëª…í™•íˆ ì „ë‹¬
5. í•œêµ­ì–´ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ ë‹µë³€
6. ê°€ëŠ¥í•˜ë©´ ìˆ«ìë‚˜ êµ¬ì²´ì  ë°ì´í„° í¬í•¨"""
            },
            {
                "role": "user",
                "content": f"""ë‹¤ìŒ ê´€ê´‘ ì—°êµ¬ ìë£Œë¥¼ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µí•´ì£¼ì„¸ìš”:

ã€ìë£Œã€‘
{context}

ã€ì§ˆë¬¸ã€‘
{question}

ã€ë‹µë³€ ìš”êµ¬ì‚¬í•­ã€‘
- í•µì‹¬ ë‚´ìš©ì„ 3-5ê°œ í¬ì¸íŠ¸ë¡œ êµ¬ì¡°í™”
- êµ¬ì²´ì ì¸ ë°ì´í„°ë‚˜ ìˆ˜ì¹˜ê°€ ìˆë‹¤ë©´ í¬í•¨
- 200-400ì ë‚´ì™¸ë¡œ ê°„ê²°í•˜ê²Œ
- ì´í•´í•˜ê¸° ì‰½ë„ë¡ ì •ë¦¬"""
            }
        ]
        
        result = self.call_openai_api(messages)
        
        if result and 'choices' in result:
            answer = result['choices'][0]['message']['content']
            return answer, sources[:3]
        else:
            # API ì‹¤íŒ¨ ì‹œ í´ë°±
            return self.structure_answer(question, retrieved_docs, sources)

    def generate_answer(self, question):
        """ë©”ì¸ ë‹µë³€ ìƒì„± (OpenAI ìš°ì„ , í´ë°± ì§€ì›)"""
        if not self.is_initialized:
            return "ì‹œìŠ¤í…œì´ ì•„ì§ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.", []
        
        try:
            # OpenAI API ì‚¬ìš© ì‹œë„
            if self.api_key:
                return self.generate_answer_with_openai(question)
            else:
                # í´ë°±: ê°œì„ ëœ êµ¬ì¡°í™” ë‹µë³€
                return super().generate_answer(question)
                
        except Exception as e:
            logger.error(f"ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")
            return "ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.", []

# ë¬´ë£Œ ëŒ€ì•ˆ: Hugging Face Inference API
class HuggingFaceRAG(ImprovedTourismRAG):
    def __init__(self, data_folder="./data", similarity_threshold=0.1):
        super().__init__(data_folder, similarity_threshold)
        
    def call_huggingface_api(self, text, model="microsoft/DialoGPT-medium"):
        """Hugging Face ë¬´ë£Œ API í˜¸ì¶œ"""
        # ë¬´ë£Œ ëª¨ë¸ ì‚¬ìš© (ì œí•œì )
        try:
            # ê°„ë‹¨í•œ í…ìŠ¤íŠ¸ ìš”ì•½ ì‹œë„
            return self.simple_text_processing(text)
        except Exception as e:
            logger.error(f"Hugging Face API ì˜¤ë¥˜: {e}")
            return None
    
    def simple_text_processing(self, text):
        """ê°„ë‹¨í•œ í…ìŠ¤íŠ¸ ì²˜ë¦¬"""
        sentences = text.split('.')
        # ì¤‘ìš”í•´ ë³´ì´ëŠ” ë¬¸ì¥ë“¤ ì„ íƒ (í‚¤ì›Œë“œ ê¸°ë°˜)
        important_keywords = ['íŠ¹ì„±', 'íŠ¹ì§•', 'í•œë¥˜', 'ê´€ê´‘ê°', 'ì—¬í–‰ê°', 'ì†Œë¹„', 'ë°©ë¬¸']
        
        important_sentences = []
        for sentence in sentences:
            if any(keyword in sentence for keyword in important_keywords):
                important_sentences.append(sentence.strip())
        
        return '. '.join(important_sentences[:3])
    
    def generate_answer(self, question):
        """Hugging Face ê¸°ë°˜ ë‹µë³€ ìƒì„±"""
        retrieved_docs, sources = self.query(question, top_k=3)
        
        if not retrieved_docs:
            return "ê´€ë ¨ëœ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.", []
        
        # í…ìŠ¤íŠ¸ ì²˜ë¦¬ ë° ìš”ì•½
        context = " ".join(retrieved_docs)
        processed_text = self.simple_text_processing(context)
        
        if processed_text:
            # êµ¬ì¡°í™”ëœ ë‹µë³€ ìƒì„±
            lines = processed_text.split('.')
            formatted_answer = "ğŸ“‹ ì£¼ìš” ë‚´ìš©:\n\n"
            for i, line in enumerate(lines[:4], 1):
                if line.strip():
                    formatted_answer += f"{i}. {line.strip()}\n"
            
            return formatted_answer, sources[:3]
        else:
            return super().generate_answer(question)